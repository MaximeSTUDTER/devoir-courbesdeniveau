{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devoir de Calcul Différentiel : Courbes de niveau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préambule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dépendances logicielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Différentiation automatique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(f):\n",
    "    g = autograd.grad\n",
    "    def grad_f(x, y):\n",
    "        return np.array([g(f, 0)(x, y), g(f, 1)(x, y)])\n",
    "    return grad_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J(f):\n",
    "    j = autograd.jacobian\n",
    "    def J_f(x, y):\n",
    "        return np.array([j(f, 0)(x, y), j(f, 1)(x, y)]).T\n",
    "    return J_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble de niveaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des ensembles de niveaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soit $c \\in \\mathbb{R}$, l'ensemble $\\{c\\}$ est un fermé. La fonction $f$ étant continue, la courbe de niveau $c$, qui est en fait $f^-1(\\{c\\})$ est également un fermé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le vecteur $T = \\frac {1} {\\|\\nabla f(x_0)\\|} \\begin{pmatrix} \\partial_2 f(x_0) \\\\ -\\partial_1 f(x_0) \\end{pmatrix}$ est le vecteur normalisé orthogonal au gradient donc tangent à la courbe au point $x_0$. Ainsi, $p(x_1,x_2)$ correspond au produit scalaire entre $T$ et le vecteur $MM_0 = \\begin{pmatrix} x_1 - x_{10} \\\\ x_2 - x_{20} \\end{pmatrix}$, ce qui géométriquement correspond à la projection orthogonale de $MM_0$ sur  $T$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
